basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
devtools::load_all(".")
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
system.time(lapply(cases, function(x) x$run_workflow(rf_object = model)))
devtools::load_all(".")
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
system.time(lapply(cases, function(x) x$run_workflow(rf_object = model)))
devtools::load_all(".")
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
system.time(lapply(cases, function(x) x$run_workflow(rf_object = model)))
devtools::load_all(".")
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
system.time(lapply(cases, function(x) x$run_workflow(rf_object = model)))
devtools::load_all(".")
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process test case -----
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
system.time(lapply(cases, function(x) x$run_workflow(rf_object = model)))
system.time(lapply(cases, render_report, template = "./Data/netid_report.Rmd", out_dir = "./testing/"))
devtools::load_all(".")
system.time(lapply(cases, render_report, template = "./Data/netid_report.Rmd", out_dir = "./testing/"))
browseVignettes()
browseVignettes()
devtools::load_all(".")
rm(list = ls())
t0 <- Sys.time()
# load Random Forest model
load("./testing/Perfect_RF_Model.rData")
# scan input files
input_dir <- "./testing/test-upload-faulty/"
upload <- scan_directory(upload_dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
cases <- lapply(as.list(basenames), FUN = ClassificationCase$new, input_dir)
lapply(cases, function(x) x$run_workflow(rf_object = model))
lapply(cases, render_report, template = "./Data/netid_report.Rmd", out_dir = "./testing/")
t1 <- Sys.time() - t0
t1
net_id_v1 <- model
save(net_id_v1, file = "./Data/NetID_v1.RData")
devtools::load_all(".")
# load Random Forest model
model <- crystalmeth::net_id_v1
devtools::load_all(".")
devtools::use_data_raw()
use_data_raw()
?devtools::use_data_raw()
?use_data_raw()
usethis::use_data_raw()
setwd("./data-raw/")
?use_data
??use_data
library(usethis)
??use_data
??use_data
?use_data
# Data for normal controls was downloaded from
# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE86833
# and contains n = 5 matched samples of cord blood for both platforms
library(minfi)
library(conumee)
# Data for normal controls was downloaded from
# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE86833
# and contains n = 5 matched samples of cord blood for both platforms
library(minfi)
library(conumee)
ctrl_dir <- "./data-raw/controls450k/"
ctrl_basenames <- list.files(path = ctrl_dir, pattern = "_Grn.idat")
ctrl_basenames <- stringr::str_remove(ctrl_basenames, "_Grn.idat")
ctrl_raw <- minfi::read.metharray(basenames = file.path(ctrl_dir, ctrl_basenames))
NormalControls450k <- minfi::preprocessIllumina(ctrl_raw)
usethis::use_data(NormalControls450k, overwrite = TRUE)
ctrl_dir <- "./data-raw/controlsEpic/"
ctrl_basenames <- list.files(path = ctrl_dir, pattern = "_Grn.idat")
ctrl_basenames <- stringr::str_remove(ctrl_basenames, "_Grn.idat")
ctrl_raw <- minfi::read.metharray(basenames = file.path(ctrl_dir, ctrl_basenames))
NormalControlsEpic <- minfi::preprocessIllumina(ctrl_raw)
usethis::use_data(NormalControlsEpic, overwrite = TRUE)
ConumeeAnno450k <- conumee::CNV.create_anno(array_type = "450k")
usethis::use_data(ConumeeAnno450k, overwrite = TRUE)
ConumeeAnnoEpic <- conumee::CNV.create_anno(array_type = "EPIC")
usethis::use_data(NormalControlsEpic, overwrite = TRUE)
usethis::use_data(NormalControlsEpic, overwrite = TRUE)
ls()
NormalControls450k
ls()
devtools::load_all(".")
?NormalControlsEpic
devtools::load_all(".")
devtools::load_all(".")
?NormalControlsEpic
??NormalControlsEpic
crystalmeth::NormalControls450k
?crystalmeth::NormalControls450k
??crystalmeth::NormalControls450k
library(crystalmeth)
??NormalControlsEpic
?NormalControlsEpic
?NormalControlsEpic
?NormalControls450k
library(minfi)
library(conumee)
# Annotation for Conumee CNV plots -----
# Illumina 450K platform
ConumeeAnno450k <- conumee::CNV.create_anno(array_type = "450k")
usethis::use_data(ConumeeAnno450k, overwrite = TRUE)
# Illumina EPIC platform
ConumeeAnnoEpic <- conumee::CNV.create_anno(array_type = "EPIC")
usethis::use_data(NormalControlsEpic, overwrite = TRUE)
usethis::use_data(ConumeeAnnoEPIC, overwrite = TRUE)
usethis::use_data(ConumeeAnnoEpic, overwrite = TRUE)
# Illumina EPIC platform
ctrl_dir <- "./data-raw/controlsEpic/"
ctrl_basenames <- list.files(path = ctrl_dir, pattern = "_Grn.idat")
ctrl_basenames <- stringr::str_remove(ctrl_basenames, "_Grn.idat")
ctrl_raw <- minfi::read.metharray(basenames = file.path(ctrl_dir, ctrl_basenames))
NormalControlsEpic <- minfi::preprocessIllumina(ctrl_raw)
usethis::use_data(NormalControlsEpic, overwrite = TRUE)
load("./data/RFpurify_ABSOLUTE.RData")
RFpurify_ABSOLUTE
rm(ctrl_basenames)
rm(ctrl_dir)
rm(ctrl_raw)
rm(NormalControlsEpic)
rm(RFpurify_ABSOLUTE)
ls()
ConumeeAnno450k
devtools::document()
?ConumeeAnnao450k
?ConumeeAnno450k
?
devtools::load_all(".")
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
upload
devtools::load_all(".")
?scan_directory
?scan_directory
devtools::document()
devtools::load_all(".")
?scan_directory
devtools::document()
?scan_directory
devtools::document()
?scan_directory
devtools::document()
?scan_directory
devtools::document()
devtools::document()
?scan_directory
devtools::document()
?scan_directory
devtools::document()
devtools::document()
?get_all
devtools::document()
?get_all
devtools::document()
?get_all
devtools::document()
?get_all
devtools::document()
?get_green_only
devtools::document()
devtools::document()
devtools::document()
devtools::document()
?get_red_only
?get_invalid
devtools::document()
?get_cases
?get_basename
upload %>% get_cases
upload %>% get_files
upload %>% get_files()
upload %>% get_all()
devtools::document()
?get_basename
devtools::document()
devtools::document()
?guess_array_type
devtools::document()
?impute_random
devtools::document()
?get_basename
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
basenames
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
test
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
devtools::load_all(".")
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
devtools::load_all(".")
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
package?crystalmeth
package?crystalmeth
package?crystalmeth
devtools::load_all(".")
devtools::load_all(".")
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
devtools::load_all(".")
package?crystalmeth
devtools::load_all(".")
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
package?crystalmeth
?generate_report
devtools::load_all(".")
?render_report
?crystalmeth
?crystalmeth
devtools::load_all(".")
?crystalmeth
devtools::load_all(".")
?crystalmeth
?crystalmeth
version()
package.version("R6")
?ClassificationCase
minfi::preprocessIllumina()
minfi?preprocessIllumina
?preprocessIllumina
case$purity
?minfi::read.metharray
?ClassificationCase
?ClassificationCase
?ClassificationCase
?ClassificationCase
?ClassificationCase
?ClassificationCase
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# TODO functionality:
# * Conumee detail plot
# * choice of preprocessing function
# * choice of imputation function
# TODO best practices:
# move CNV normal controls to separate package (package size...)
# install RF_Purify instead of integrating it...
# TODO package development:
# * document functions (exporting??)
# * document class
# * write vignette (use as README.md)
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
devtools::load_all(".")
# TODO functionality:
# * Conumee detail plot
# * choice of preprocessing function
# * choice of imputation function
# TODO best practices:
# move CNV normal controls to separate package (package size...)
# install RF_Purify instead of integrating it...
# TODO package development:
# * document functions (exporting??)
# * document class
# * write vignette (use as README.md)
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
library(tidyverse)
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
library(crystalmeth)
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
devtools::load_all(".")
t0 <- Sys.time() # takes about 1.2 mins for complete processing of two samples
# load Random Forest model
load("./temp/NetID_v1.RData")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
upload <- scan_directory(dir = input_dir)
basenames <- upload %>% get_cases()
# process cases
case <- ClassificationCase$new(basenames[1], input_dir)
case$run_workflow(rf_object = net_id_v1)
test <- render_report(case, template = "./temp/netid_report.Rmd", out_dir = "./temp/")
# gather location of output PDFs & prepare download
test
t1 <- Sys.time() - t0
t1
devtools::use_vignette("crystalmeth")
use_vignette("crystalmeth")
usethis::use_vignette("crystalmeth")
t1
browseVignettes("conumee")
browseVignettes("usethis")
browseVignettes("usethat")
browseVignettes("use_that")
browseVignettes("stringr")
devtools::load_all(".")
# scan input files
input_dir <- "./temp/test-upload-faulty/"
files <- scan_directory(dir = input_dir)
crystalmeth::scan_directory()
devtools::load_all(".")
library(crystalmeth)
library(crystalmeth)
library(tidyverse)
input_dir <- "./temp/test-upload-faulty/"
files <- crystalmeth::scan_directory(dir = input_dir)
library(crystalmeth)
library(tidyverse)
input_dir <- "./temp/test-upload-faulty/"
files <- crystalmeth::scan_directory(dir = input_dir)
library(crystalmeth)
library(crystalmeth)
library(tidyverse)
input_dir <- "./temp/test-upload-faulty/"
files <- crystalmeth::scan_directory(dir = input_dir)
input_dir <- "./temp/test-upload-faulty/"
files <- scan_directory(dir = input_dir)
input_dir <- "../temp/input_data/"
files <- scan_directory(dir = input_dir)
# take a look at the output of scan_directory()
files
# get_cases() will extract the basenames with matching _Red.idat and _Grn.idat files
basenames <- files %>% get_cases()
# Let's create a new Classification case object for one case
case <- ClassificationCase$new(basename = basenames[1], path = input_dir)
# Let's create a new Classification case object for one of the cases
case <- ClassificationCase$new(basename = basenames[1], path = input_dir)
# running the above command will produce messages about the input file checks which are suppressed here
unlink('vignettes/crystalmeth_cache', recursive = TRUE)
output_directory = "../temp/reports/"
template_path = "../temp/netid_report.Rmd"
# note that render_report() returns the location(s) of the output files
out_files <- render_report(case, template = template_path, out_dir = output_directory)
library(crystalmeth)
library(tidyverse)
input_dir <- "../temp/input_data/"
files <- scan_directory(dir = input_dir)
# get_cases() will extract the basenames with matching _Red.idat and _Grn.idat files
basenames <- files %>% get_cases()
basenames
# Let's create a new Classification case object for one of the cases
case <- ClassificationCase$new(basename = basenames[1], path = input_dir)
# messages are suppressed in this code chunk
load("../temp/NetID_v1.RData") # load net_id_v1 (randomForest classifier)
# this command will run the full workflow
case$run_workflow(rf_object = net_id_v1)
# messages are suppressed in this code chunk
output_directory = "../temp/reports/"
template_path = "../temp/netid_report.Rmd"
# note that render_report() returns the location(s) of the output files
out_files <- render_report(case, template = template_path, out_dir = output_directory)
out_files
devtools::build()
devtools::build_vignettes()
